/* Generated by: CongoCC Parser Generator. SqlExprParserLexer.java  */
package net.magneticpotato.sqlexpr.congocc.parser;

import net.magneticpotato.sqlexpr.congocc.parser.Token.TokenType;
import static net.magneticpotato.sqlexpr.congocc.parser.Token.TokenType.*;
import java.util.*;


public class SqlExprParserLexer extends TokenSource {
    private static MatcherHook MATCHER_HOOK;

    // this cannot be initialized here, since hook must be set afterwards
    public enum LexicalState {
        DEFAULT
    }

    LexicalState lexicalState = LexicalState.values()[0];
    EnumSet<TokenType> activeTokenTypes = null;
    // Token types that are "regular" tokens that participate in parsing,
    // i.e. declared as TOKEN
    static final EnumSet<TokenType> regularTokens = EnumSet.of(EOF, NOT, AND, OR, BETWEEN, LIKE, ESCAPE, IN, IS, TRUE, FALSE, NULL, _TOKEN_17, _TOKEN_18, _TOKEN_19, _TOKEN_20, _TOKEN_21, _TOKEN_22, _TOKEN_23, _TOKEN_24, _TOKEN_25, _TOKEN_26, _TOKEN_27, _TOKEN_28, _TOKEN_29, _TOKEN_30, DECIMAL_LITERAL, HEX_LITERAL, OCTAL_LITERAL, FLOATING_POINT_LITERAL, STRING_LITERAL, ID);
    // Token types that do not participate in parsing
    // i.e. declared as UNPARSED (or SPECIAL_TOKEN)
    static final EnumSet<TokenType> unparsedTokens = EnumSet.of(_TOKEN_1, _TOKEN_2, _TOKEN_3, _TOKEN_4, _TOKEN_5);
    // Tokens that are skipped, i.e. SKIP
    static final EnumSet<TokenType> skippedTokens = EnumSet.of(LINE_COMMENT, BLOCK_COMMENT);
    // Tokens that correspond to a MORE, i.e. that are pending
    // additional input
    static final EnumSet<TokenType> moreTokens = EnumSet.noneOf(TokenType.class);

    public SqlExprParserLexer(CharSequence input) {
        this("input", input);
    }

    /**
    * @param inputSource just the name of the input source (typically the filename)
    * that will be used in error messages and so on.
    * @param input the input
    */
    public SqlExprParserLexer(String inputSource, CharSequence input) {
        this(inputSource, input, LexicalState.DEFAULT, 1, 1);
    }

    /**
    * @param inputSource just the name of the input source (typically the filename) that
    * will be used in error messages and so on.
    * @param input the input
    * @param lexState The starting lexical state, may be null to indicate the default
    * starting state
    * @param startingLine The line number at which we are starting for the purposes of location/error messages. In most
    * normal usage, this is 1.
    * @param startingColumn number at which we are starting for the purposes of location/error messages. In most normal
    * usages this is 1.
    */
    public SqlExprParserLexer(String inputSource, CharSequence input, LexicalState lexState, int startingLine, int startingColumn) {
        super(inputSource, input, startingLine, startingColumn, 1, true, false, false, "");
        if (lexicalState != null) switchTo(lexState);
    }

    public Token getNextToken(Token tok) {
        return getNextToken(tok, this.activeTokenTypes);
    }

    /**
    * The public method for getting the next token, that is
    * called by SqlExprParser.
    * It checks whether we have already cached
    * the token after this one. If not, it finally goes
    * to the NFA machinery
    */
    public Token getNextToken(Token tok, EnumSet<TokenType> activeTokenTypes) {
        if (tok == null) {
            tok = tokenizeAt(0, null, activeTokenTypes);
            cacheToken(tok);
            return tok;
        }
        Token cachedToken = tok.nextCachedToken();
        // If the cached next token is not currently active, we
        // throw it away and go back to the SqlExprParserLexer
        if (cachedToken != null && activeTokenTypes != null && !activeTokenTypes.contains(cachedToken.getType())) {
            reset(tok);
            cachedToken = null;
        }
        if (cachedToken == null) {
            Token token = tokenizeAt(tok.getEndOffset(), null, activeTokenTypes);
            cacheToken(token);
            return token;
        }
        return cachedToken;
    }


    static class MatchInfo {
        TokenType matchedType;
        int matchLength;

        @Override
        public int hashCode() {
            return Objects.hash(matchLength, matchedType);
        }

        @Override
        public boolean equals(Object obj) {
            if (this == obj) return true;
            if (obj == null) return false;
            if (getClass() != obj.getClass()) return false;
            MatchInfo other = (MatchInfo) obj;
            return matchLength == other.matchLength && matchedType == other.matchedType;
        }

    }


    @FunctionalInterface
    private interface MatcherHook {

        MatchInfo apply(LexicalState lexicalState, CharSequence input, int position, EnumSet<TokenType> activeTokenTypes, NfaFunction[] nfaFunctions, BitSet currentStates, BitSet nextStates, MatchInfo matchInfo);

    }


    /**
    * Core tokenization method. Note that this can be called from a static context.
    * Hence the extra parameters that need to be passed in.
    */
    static MatchInfo getMatchInfo(CharSequence input, int position, EnumSet<TokenType> activeTokenTypes, NfaFunction[] nfaFunctions, BitSet currentStates, BitSet nextStates, MatchInfo matchInfo) {
        if (matchInfo == null) {
            matchInfo = new MatchInfo();
        }
        if (position >= input.length()) {
            matchInfo.matchedType = EOF;
            matchInfo.matchLength = 0;
            return matchInfo;
        }
        int start = position;
        int matchLength = 0;
        TokenType matchedType = TokenType.INVALID;
        EnumSet<TokenType> alreadyMatchedTypes = EnumSet.noneOf(TokenType.class);
        if (currentStates == null) currentStates = new BitSet(110);
        else currentStates.clear();
        if (nextStates == null) nextStates = new BitSet(110);
        else nextStates.clear();
        // the core NFA loop
        do {
            // Holder for the new type (if any) matched on this iteration
            if (position > start) {
                // What was nextStates on the last iteration
                // is now the currentStates!
                BitSet temp = currentStates;
                currentStates = nextStates;
                nextStates = temp;
                nextStates.clear();
            } else {
                currentStates.set(0);
            }
            if (position >= input.length()) {
                break;
            }
            int curChar = Character.codePointAt(input, position++);
            if (curChar > 0xFFFF) position++;
            int nextActive = currentStates.nextSetBit(0);
            while (nextActive != -1) {
                TokenType returnedType = nfaFunctions[nextActive].apply(curChar, nextStates, activeTokenTypes, alreadyMatchedTypes);
                if (returnedType != null && (position - start > matchLength || returnedType.ordinal() < matchedType.ordinal())) {
                    matchedType = returnedType;
                    matchLength = position - start;
                    alreadyMatchedTypes.add(returnedType);
                }
                nextActive = currentStates.nextSetBit(nextActive + 1);
            }
            if (position >= input.length()) break;
        }
        while (!nextStates.isEmpty());
        matchInfo.matchedType = matchedType;
        matchInfo.matchLength = matchLength;
        return matchInfo;
    }

    /**
    * @param position The position at which to tokenize.
    * @param lexicalState The lexical state in which to tokenize. If this is null, it is the instance variable #lexicalState
    * @param activeTokenTypes The active token types. If this is null, they are all active.
    * @return the Token at position
    */
    final Token tokenizeAt(int position, LexicalState lexicalState, EnumSet<TokenType> activeTokenTypes) {
        if (lexicalState == null) lexicalState = this.lexicalState;
        int tokenBeginOffset = position;
        boolean inMore = false;
        int invalidRegionStart = -1;
        Token matchedToken = null;
        TokenType matchedType = null;
        // The core tokenization loop
        MatchInfo matchInfo = new MatchInfo();
        BitSet currentStates = new BitSet(110);
        BitSet nextStates = new BitSet(110);
        while (matchedToken == null) {
            if (!inMore) tokenBeginOffset = position;
            if (MATCHER_HOOK != null) {
                matchInfo = MATCHER_HOOK.apply(lexicalState, this, position, activeTokenTypes, nfaFunctions, currentStates, nextStates, matchInfo);
                if (matchInfo == null) {
                    matchInfo = getMatchInfo(this, position, activeTokenTypes, nfaFunctions, currentStates, nextStates, matchInfo);
                }
            } else {
                matchInfo = getMatchInfo(this, position, activeTokenTypes, nfaFunctions, currentStates, nextStates, matchInfo);
            }
            matchedType = matchInfo.matchedType;
            inMore = moreTokens.contains(matchedType);
            position += matchInfo.matchLength;
            if (matchedType == TokenType.INVALID) {
                if (invalidRegionStart == -1) {
                    invalidRegionStart = tokenBeginOffset;
                }
                int cp = Character.codePointAt(this, position);
                ++position;
                if (cp > 0xFFFF) ++position;
                continue;
            }
            if (invalidRegionStart != -1) {
                return new InvalidToken(this, invalidRegionStart, tokenBeginOffset);
            }
            if (skippedTokens.contains(matchedType)) {
                skipTokens(tokenBeginOffset, position);
            } else if (regularTokens.contains(matchedType) || unparsedTokens.contains(matchedType)) {
                matchedToken = Token.newToken(matchedType, this, tokenBeginOffset, position);
                matchedToken.setUnparsed(!regularTokens.contains(matchedType));
            }
        }
        return matchedToken;
    }

    /**
    * Switch to specified lexical state.
    * @param lexState the lexical state to switch to
    * @return whether we switched (i.e. we weren't already in the desired lexical state)
    */
    public boolean switchTo(LexicalState lexState) {
        if (this.lexicalState != lexState) {
            this.lexicalState = lexState;
            return true;
        }
        return false;
    }

    // Reset the token source input
    // to just after the Token passed in.
    void reset(Token t, LexicalState state) {
        uncacheTokens(t);
        if (state != null) {
            switchTo(state);
        }
    }

    void reset(Token t) {
        reset(t, null);
    }


    // NFA related code follows.
    // The functional interface that represents
    // the acceptance method of an NFA state
    @FunctionalInterface
    interface NfaFunction {

        TokenType apply(int ch, BitSet bs, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes);

    }

    private static NfaFunction[] nfaFunctions;
    // Initialize the various NFA method tables
    static {
        DEFAULT.NFA_FUNCTIONS_init();
    }

    //The Nitty-gritty of the NFA code follows.
    /**
    * Holder class for NFA code related to DEFAULT lexical state
    */
    private static class DEFAULT {

        private static TokenType getNfaIndex0(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if (ch == '\'') {
                if (validTypes == null || validTypes.contains(STRING_LITERAL)) {
                    nextStates.set(27);
                }
            } else if (ch == '-') {
                if (validTypes == null || validTypes.contains(LINE_COMMENT)) {
                    nextStates.set(33);
                }
            } else if (ch == '.') {
                if (validTypes == null || validTypes.contains(FLOATING_POINT_LITERAL)) {
                    nextStates.set(16);
                }
            } else if (ch == '/') {
                if (validTypes == null || validTypes.contains(BLOCK_COMMENT)) {
                    nextStates.set(37);
                }
            } else if (ch == '0') {
                if (validTypes == null || validTypes.contains(HEX_LITERAL)) {
                    nextStates.set(36);
                }
            }
            if (ch >= '0' && ch <= '9') {
                if (validTypes == null || validTypes.contains(FLOATING_POINT_LITERAL)) {
                    nextStates.set(35);
                }
                if (validTypes == null || validTypes.contains(FLOATING_POINT_LITERAL)) {
                    nextStates.set(8);
                }
            } else if (ch == '<') {
                if (validTypes == null || validTypes.contains(_TOKEN_22)) {
                    nextStates.set(15);
                }
                if (validTypes == null || validTypes.contains(_TOKEN_18)) {
                    nextStates.set(20);
                }
            } else if (ch == '>') {
                if (validTypes == null || validTypes.contains(_TOKEN_20)) {
                    nextStates.set(24);
                }
            } else if ((ch == 'A' || ch == 'a')) {
                if (validTypes == null || validTypes.contains(AND)) {
                    nextStates.set(34);
                }
            } else if ((ch == 'B' || ch == 'b')) {
                if (validTypes == null || validTypes.contains(BETWEEN)) {
                    nextStates.set(49);
                }
            } else if ((ch == 'E' || ch == 'e')) {
                if (validTypes == null || validTypes.contains(ESCAPE)) {
                    nextStates.set(45);
                }
            } else if ((ch == 'F' || ch == 'f')) {
                if (validTypes == null || validTypes.contains(FALSE)) {
                    nextStates.set(57);
                }
            } else if ((ch == 'I' || ch == 'i')) {
                if (validTypes == null || validTypes.contains(IS)) {
                    nextStates.set(22);
                }
                if (validTypes == null || validTypes.contains(IN)) {
                    nextStates.set(28);
                }
            } else if ((ch == 'L' || ch == 'l')) {
                if (validTypes == null || validTypes.contains(LIKE)) {
                    nextStates.set(40);
                }
            } else if ((ch == 'N' || ch == 'n')) {
                if (validTypes == null || validTypes.contains(NULL)) {
                    nextStates.set(42);
                }
                if (validTypes == null || validTypes.contains(NOT)) {
                    nextStates.set(44);
                }
            } else if ((ch == 'O' || ch == 'o')) {
                if (validTypes == null || validTypes.contains(OR)) {
                    nextStates.set(30);
                }
            } else if ((ch == 'T' || ch == 't')) {
                if (validTypes == null || validTypes.contains(TRUE)) {
                    nextStates.set(55);
                }
            }
            if ((ch == '$' || (ch >= 'A' && ch <= 'Z' || (ch == '_' || ch >= 'a' && ch <= 'z')))) {
                if (validTypes == null || validTypes.contains(ID)) {
                    nextStates.set(23);
                    type = ID;
                }
            } else if (ch == '0') {
                if (validTypes == null || validTypes.contains(OCTAL_LITERAL)) {
                    nextStates.set(29);
                    type = OCTAL_LITERAL;
                }
            } else if (ch >= '1' && ch <= '9') {
                if (validTypes == null || validTypes.contains(DECIMAL_LITERAL)) {
                    nextStates.set(1);
                    type = DECIMAL_LITERAL;
                }
            } else if (ch == '%') {
                if (validTypes == null || validTypes.contains(_TOKEN_30)) {
                    type = _TOKEN_30;
                }
            } else if (ch == '/') {
                if (validTypes == null || validTypes.contains(_TOKEN_29)) {
                    type = _TOKEN_29;
                }
            } else if (ch == '*') {
                if (validTypes == null || validTypes.contains(_TOKEN_28)) {
                    type = _TOKEN_28;
                }
            } else if (ch == '-') {
                if (validTypes == null || validTypes.contains(_TOKEN_27)) {
                    type = _TOKEN_27;
                }
            } else if (ch == '+') {
                if (validTypes == null || validTypes.contains(_TOKEN_26)) {
                    type = _TOKEN_26;
                }
            } else if (ch == ')') {
                if (validTypes == null || validTypes.contains(_TOKEN_25)) {
                    type = _TOKEN_25;
                }
            } else if (ch == ',') {
                if (validTypes == null || validTypes.contains(_TOKEN_24)) {
                    type = _TOKEN_24;
                }
            } else if (ch == '(') {
                if (validTypes == null || validTypes.contains(_TOKEN_23)) {
                    type = _TOKEN_23;
                }
            } else if (ch == '<') {
                if (validTypes == null || validTypes.contains(_TOKEN_21)) {
                    type = _TOKEN_21;
                }
            } else if (ch == '>') {
                if (validTypes == null || validTypes.contains(_TOKEN_19)) {
                    type = _TOKEN_19;
                }
            } else if (ch == '=') {
                if (validTypes == null || validTypes.contains(_TOKEN_17)) {
                    type = _TOKEN_17;
                }
            } else if (ch == '\f') {
                if (validTypes == null || validTypes.contains(_TOKEN_5)) {
                    type = _TOKEN_5;
                }
            } else if (ch == '\r') {
                if (validTypes == null || validTypes.contains(_TOKEN_4)) {
                    type = _TOKEN_4;
                }
            } else if (ch == '\n') {
                if (validTypes == null || validTypes.contains(_TOKEN_3)) {
                    type = _TOKEN_3;
                }
            } else if (ch == '\t') {
                if (validTypes == null || validTypes.contains(_TOKEN_2)) {
                    type = _TOKEN_2;
                }
            } else if (ch == ' ') {
                if (validTypes == null || validTypes.contains(_TOKEN_1)) {
                    type = _TOKEN_1;
                }
            }
            return type;
        }

        private static TokenType getNfaIndex1(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if (ch >= '0' && ch <= '9') {
                nextStates.set(1);
                type = DECIMAL_LITERAL;
            } else if ((ch == 'L' || ch == 'l')) {
                type = DECIMAL_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex2(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch >= 0x0 && ch <= '\t' || (ch == 0xb || ch == '\f' || ch >= 0xe))) {
                nextStates.set(2);
            } else if (ch == '\r') {
                nextStates.set(3);
            } else if (ch == '\n') {
                type = LINE_COMMENT;
            }
            if (ch == '\r') {
                type = LINE_COMMENT;
            }
            return type;
        }

        private static TokenType getNfaIndex3(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '\n') {
                return LINE_COMMENT;
            }
            return null;
        }

        private static TokenType getNfaIndex4(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'D' || ch == 'd')) {
                return AND;
            }
            return null;
        }

        private static TokenType getNfaIndex5(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch == '+' || ch == '-')) {
                nextStates.set(6);
            } else if (ch >= '0' && ch <= '9') {
                nextStates.set(6);
                type = FLOATING_POINT_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex6(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch >= '0' && ch <= '9') {
                nextStates.set(6);
                return FLOATING_POINT_LITERAL;
            }
            return null;
        }

        private static TokenType getNfaIndex7(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch >= '0' && ch <= '9' || (ch >= 'A' && ch <= 'F' || ch >= 'a' && ch <= 'f'))) {
                nextStates.set(7);
                return HEX_LITERAL;
            }
            return null;
        }

        private static TokenType getNfaIndex8(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if (ch >= '0' && ch <= '9') {
                nextStates.set(8);
            } else if (ch == '.') {
                nextStates.set(9);
                type = FLOATING_POINT_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex9(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch == 'E' || ch == 'e')) {
                nextStates.set(10);
            } else if (ch >= '0' && ch <= '9') {
                nextStates.set(9);
                type = FLOATING_POINT_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex10(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch == '+' || ch == '-')) {
                nextStates.set(11);
            } else if (ch >= '0' && ch <= '9') {
                nextStates.set(11);
                type = FLOATING_POINT_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex11(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch >= '0' && ch <= '9') {
                nextStates.set(11);
                return FLOATING_POINT_LITERAL;
            }
            return null;
        }

        private static TokenType getNfaIndex12(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch >= 0x0 && ch <= ')' || (ch >= '+' && ch <= '.' || ch >= '0'))) {
                nextStates.set(39);
            } else if (ch == '*') {
                nextStates.set(12);
            } else if (ch == '/') {
                type = BLOCK_COMMENT;
            }
            return type;
        }

        private static TokenType getNfaIndex13(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                return LIKE;
            }
            return null;
        }

        private static TokenType getNfaIndex14(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'L' || ch == 'l')) {
                return NULL;
            }
            return null;
        }

        private static TokenType getNfaIndex15(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '=') {
                return _TOKEN_22;
            }
            return null;
        }

        private static TokenType getNfaIndex16(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch >= '0' && ch <= '9') {
                nextStates.set(17);
                return FLOATING_POINT_LITERAL;
            }
            return null;
        }

        private static TokenType getNfaIndex17(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch == 'E' || ch == 'e')) {
                nextStates.set(18);
            } else if (ch >= '0' && ch <= '9') {
                nextStates.set(17);
                type = FLOATING_POINT_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex18(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch == '+' || ch == '-')) {
                nextStates.set(19);
            } else if (ch >= '0' && ch <= '9') {
                nextStates.set(19);
                type = FLOATING_POINT_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex19(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch >= '0' && ch <= '9') {
                nextStates.set(19);
                return FLOATING_POINT_LITERAL;
            }
            return null;
        }

        private static TokenType getNfaIndex20(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '>') {
                return _TOKEN_18;
            }
            return null;
        }

        private static TokenType getNfaIndex21(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'T' || ch == 't')) {
                return NOT;
            }
            return null;
        }

        private static TokenType getNfaIndex22(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'S' || ch == 's')) {
                return IS;
            }
            return null;
        }

        private static TokenType getNfaIndex23(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == '$' || (ch >= '0' && ch <= '9' || (ch >= 'A' && ch <= 'Z' || (ch == '_' || ch >= 'a' && ch <= 'z'))))) {
                nextStates.set(23);
                return ID;
            }
            return null;
        }

        private static TokenType getNfaIndex24(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '=') {
                return _TOKEN_20;
            }
            return null;
        }

        private static TokenType getNfaIndex25(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                return ESCAPE;
            }
            return null;
        }

        private static TokenType getNfaIndex26(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'N' || ch == 'n')) {
                return BETWEEN;
            }
            return null;
        }

        private static TokenType getNfaIndex27(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            TokenType type = null;
            if ((ch >= 0x0 && ch <= '&' || ch >= '(')) {
                nextStates.set(27);
            } else if (ch == '\'') {
                nextStates.set(54);
                type = STRING_LITERAL;
            }
            return type;
        }

        private static TokenType getNfaIndex28(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'N' || ch == 'n')) {
                return IN;
            }
            return null;
        }

        private static TokenType getNfaIndex29(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch >= '0' && ch <= '7') {
                nextStates.set(29);
                return OCTAL_LITERAL;
            }
            return null;
        }

        private static TokenType getNfaIndex30(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'R' || ch == 'r')) {
                return OR;
            }
            return null;
        }

        private static TokenType getNfaIndex31(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                return TRUE;
            }
            return null;
        }

        private static TokenType getNfaIndex32(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                return FALSE;
            }
            return null;
        }

        private static TokenType getNfaIndex33(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '-') {
                nextStates.set(2);
            }
            return null;
        }

        private static TokenType getNfaIndex34(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'N' || ch == 'n')) {
                nextStates.set(4);
            }
            return null;
        }

        private static TokenType getNfaIndex35(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch >= '0' && ch <= '9') {
                nextStates.set(35);
            } else if ((ch == 'E' || ch == 'e')) {
                nextStates.set(5);
            }
            return null;
        }

        private static TokenType getNfaIndex36(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'X' || ch == 'x')) {
                nextStates.set(7);
            }
            return null;
        }

        private static TokenType getNfaIndex37(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '*') {
                nextStates.set(38);
            }
            return null;
        }

        private static TokenType getNfaIndex38(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch >= 0x0 && ch <= ')' || ch >= '+')) {
                nextStates.set(38);
            } else if (ch == '*') {
                nextStates.set(12);
            }
            return null;
        }

        private static TokenType getNfaIndex39(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch >= 0x0 && ch <= ')' || ch >= '+')) {
                nextStates.set(39);
            } else if (ch == '*') {
                nextStates.set(12);
            }
            return null;
        }

        private static TokenType getNfaIndex40(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'I' || ch == 'i')) {
                nextStates.set(41);
            }
            return null;
        }

        private static TokenType getNfaIndex41(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'K' || ch == 'k')) {
                nextStates.set(13);
            }
            return null;
        }

        private static TokenType getNfaIndex42(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'U' || ch == 'u')) {
                nextStates.set(43);
            }
            return null;
        }

        private static TokenType getNfaIndex43(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'L' || ch == 'l')) {
                nextStates.set(14);
            }
            return null;
        }

        private static TokenType getNfaIndex44(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'O' || ch == 'o')) {
                nextStates.set(21);
            }
            return null;
        }

        private static TokenType getNfaIndex45(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'S' || ch == 's')) {
                nextStates.set(46);
            }
            return null;
        }

        private static TokenType getNfaIndex46(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'C' || ch == 'c')) {
                nextStates.set(47);
            }
            return null;
        }

        private static TokenType getNfaIndex47(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'A' || ch == 'a')) {
                nextStates.set(48);
            }
            return null;
        }

        private static TokenType getNfaIndex48(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'P' || ch == 'p')) {
                nextStates.set(25);
            }
            return null;
        }

        private static TokenType getNfaIndex49(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                nextStates.set(50);
            }
            return null;
        }

        private static TokenType getNfaIndex50(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'T' || ch == 't')) {
                nextStates.set(51);
            }
            return null;
        }

        private static TokenType getNfaIndex51(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'W' || ch == 'w')) {
                nextStates.set(52);
            }
            return null;
        }

        private static TokenType getNfaIndex52(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                nextStates.set(53);
            }
            return null;
        }

        private static TokenType getNfaIndex53(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'E' || ch == 'e')) {
                nextStates.set(26);
            }
            return null;
        }

        private static TokenType getNfaIndex54(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if (ch == '\'') {
                nextStates.set(27);
            }
            return null;
        }

        private static TokenType getNfaIndex55(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'R' || ch == 'r')) {
                nextStates.set(56);
            }
            return null;
        }

        private static TokenType getNfaIndex56(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'U' || ch == 'u')) {
                nextStates.set(31);
            }
            return null;
        }

        private static TokenType getNfaIndex57(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'A' || ch == 'a')) {
                nextStates.set(58);
            }
            return null;
        }

        private static TokenType getNfaIndex58(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'L' || ch == 'l')) {
                nextStates.set(59);
            }
            return null;
        }

        private static TokenType getNfaIndex59(int ch, BitSet nextStates, EnumSet<TokenType> validTypes, EnumSet<TokenType> alreadyMatchedTypes) {
            if ((ch == 'S' || ch == 's')) {
                nextStates.set(32);
            }
            return null;
        }

        private static void NFA_FUNCTIONS_init() {
            NfaFunction[] functions = new NfaFunction[] {DEFAULT::getNfaIndex0, DEFAULT::getNfaIndex1,
            DEFAULT::getNfaIndex2, DEFAULT::getNfaIndex3, DEFAULT::getNfaIndex4, DEFAULT::getNfaIndex5,
            DEFAULT::getNfaIndex6, DEFAULT::getNfaIndex7, DEFAULT::getNfaIndex8, DEFAULT::getNfaIndex9,
            DEFAULT::getNfaIndex10, DEFAULT::getNfaIndex11, DEFAULT::getNfaIndex12,
            DEFAULT::getNfaIndex13, DEFAULT::getNfaIndex14, DEFAULT::getNfaIndex15,
            DEFAULT::getNfaIndex16, DEFAULT::getNfaIndex17, DEFAULT::getNfaIndex18,
            DEFAULT::getNfaIndex19, DEFAULT::getNfaIndex20, DEFAULT::getNfaIndex21,
            DEFAULT::getNfaIndex22, DEFAULT::getNfaIndex23, DEFAULT::getNfaIndex24,
            DEFAULT::getNfaIndex25, DEFAULT::getNfaIndex26, DEFAULT::getNfaIndex27,
            DEFAULT::getNfaIndex28, DEFAULT::getNfaIndex29, DEFAULT::getNfaIndex30,
            DEFAULT::getNfaIndex31, DEFAULT::getNfaIndex32, DEFAULT::getNfaIndex33,
            DEFAULT::getNfaIndex34, DEFAULT::getNfaIndex35, DEFAULT::getNfaIndex36,
            DEFAULT::getNfaIndex37, DEFAULT::getNfaIndex38, DEFAULT::getNfaIndex39,
            DEFAULT::getNfaIndex40, DEFAULT::getNfaIndex41, DEFAULT::getNfaIndex42,
            DEFAULT::getNfaIndex43, DEFAULT::getNfaIndex44, DEFAULT::getNfaIndex45,
            DEFAULT::getNfaIndex46, DEFAULT::getNfaIndex47, DEFAULT::getNfaIndex48,
            DEFAULT::getNfaIndex49, DEFAULT::getNfaIndex50, DEFAULT::getNfaIndex51,
            DEFAULT::getNfaIndex52, DEFAULT::getNfaIndex53, DEFAULT::getNfaIndex54,
            DEFAULT::getNfaIndex55, DEFAULT::getNfaIndex56, DEFAULT::getNfaIndex57,
            DEFAULT::getNfaIndex58, DEFAULT::getNfaIndex59};
            nfaFunctions = functions;
        }

    }

}


