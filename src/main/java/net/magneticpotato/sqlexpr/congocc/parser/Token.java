/*
* Generated by: CongoCC Parser Generator. Token.java
*/
package net.magneticpotato.sqlexpr.congocc.parser;

import net.magneticpotato.sqlexpr.congocc.parser.ast.*;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Iterator;
import java.util.List;


public class Token implements CharSequence, Node.TerminalNode {

    public enum TokenType implements Node.NodeType {
        EOF, _TOKEN_1(" "), _TOKEN_2("\t"), _TOKEN_3("\n"), _TOKEN_4("\r"), _TOKEN_5("\f"),
        NOT, AND, OR, BETWEEN, LIKE, ESCAPE, IN, IS, TRUE, FALSE, NULL, _TOKEN_17("="),
        _TOKEN_18("<>"), _TOKEN_19(">"), _TOKEN_20(">="), _TOKEN_21("<"), _TOKEN_22("<="),
        _TOKEN_23("("), _TOKEN_24(","), _TOKEN_25(")"), _TOKEN_26("+"), _TOKEN_27("-"),
        _TOKEN_28("*"), _TOKEN_29("/"), _TOKEN_30("%"), LINE_COMMENT, BLOCK_COMMENT,
        DECIMAL_LITERAL, HEX_LITERAL, OCTAL_LITERAL, FLOATING_POINT_LITERAL, STRING_LITERAL,
        ID, DUMMY, INVALID;

        TokenType() {
        }

        TokenType(String literalString) {
            this.literalString = literalString;
        }

        private String literalString;

        public String getLiteralString() {
            return literalString;
        }

        public boolean isUndefined() {
            return this == DUMMY;
        }

        public boolean isInvalid() {
            return this == INVALID;
        }

        public boolean isEOF() {
            return this == EOF;
        }

    }

    private SqlExprParserLexer tokenSource;
    private TokenType type = TokenType.DUMMY;
    private int beginOffset;
    private int endOffset;
    private boolean unparsed;
    private Node parent;

    public void truncate(int amount) {
        int newEndOffset = Math.max(getBeginOffset(), getEndOffset() - amount);
        setEndOffset(newEndOffset);
    }

    /**
    * It would be extremely rare that an application
    * programmer would use this method. It needs to
    * be public because it is part of the net.magneticpotato.sqlexpr.congocc.parser.Node interface.
    */
    public void setBeginOffset(int beginOffset) {
        this.beginOffset = beginOffset;
    }

    /**
    * It would be extremely rare that an application
    * programmer would use this method. It needs to
    * be public because it is part of the net.magneticpotato.sqlexpr.congocc.parser.Node interface.
    */
    public void setEndOffset(int endOffset) {
        this.endOffset = endOffset;
    }

    /**
    * @return the SqlExprParserLexer object that handles
    * location info for the tokens.
    */
    public SqlExprParserLexer getTokenSource() {
        return this.tokenSource;
    }

    /**
    * It should be exceedingly rare that an application
    * programmer needs to use this method.
    */
    public void setTokenSource(TokenSource tokenSource) {
        this.tokenSource = (SqlExprParserLexer) tokenSource;
    }

    public boolean isInvalid() {
        return getType().isInvalid();
    }

    /**
    * Return the TokenType of this Token object
    */
    @Override
    public TokenType getType() {
        return type;
    }

    protected void setType(TokenType type) {
        this.type = type;
    }

    /**
    * @return whether this Token represent actual input or was it inserted somehow?
    */
    public boolean isVirtual() {
        return type == TokenType.EOF;
    }

    /**
    * @return Did we skip this token in parsing?
    */
    public boolean isSkipped() {
        return false;
    }

    public int getBeginOffset() {
        return beginOffset;
    }

    public int getEndOffset() {
        return endOffset;
    }

    /**
    * @return the next _cached_ regular (i.e. parsed) token
    * or null
    */
    @Override
    public final Token getNext() {
        return getNextParsedToken();
    }

    /**
    * @return the previous regular (i.e. parsed) token
    * or null
    */
    public final Token getPrevious() {
        Token result = previousCachedToken();
        while (result != null && result.isUnparsed()) {
            result = result.previousCachedToken();
        }
        return result;
    }

    /**
    * @return the next regular (i.e. parsed) token
    */
    private Token getNextParsedToken() {
        Token result = nextCachedToken();
        while (result != null && result.isUnparsed()) {
            result = result.nextCachedToken();
        }
        return result;
    }

    /**
    * @return the next token of any sort (parsed or unparsed or invalid)
    */
    public Token nextCachedToken() {
        if (getType() == TokenType.EOF) return null;
        SqlExprParserLexer tokenSource = getTokenSource();
        return tokenSource != null ? (Token) tokenSource.nextCachedToken(getEndOffset()) : null;
    }

    public Token previousCachedToken() {
        if (getTokenSource() == null) return null;
        return (Token) getTokenSource().previousCachedToken(getBeginOffset());
    }

    Token getPreviousToken() {
        return previousCachedToken();
    }

    public Token replaceType(TokenType type) {
        Token result = newToken(type, getTokenSource(), getBeginOffset(), getEndOffset());
        getTokenSource().cacheToken(result);
        return result;
    }

    public String getSource() {
        if (type == TokenType.EOF) return "";
        SqlExprParserLexer ts = getTokenSource();
        int beginOffset = getBeginOffset();
        int endOffset = getEndOffset();
        return ts == null || beginOffset <= 0 && endOffset <= 0 ? null : ts.getText(beginOffset, endOffset);
    }

    protected Token() {
    }

    public Token(TokenType type, SqlExprParserLexer tokenSource, int beginOffset, int endOffset) {
        this.type = type;
        this.tokenSource = tokenSource;
        this.beginOffset = beginOffset;
        this.endOffset = endOffset;
    }

    public boolean isUnparsed() {
        return unparsed;
    }

    public void setUnparsed(boolean unparsed) {
        this.unparsed = unparsed;
    }

    /**
    * @return An iterator of the tokens preceding this one.
    */
    public Iterator<Token> precedingTokens() {
        return new Iterator<Token>() {
            Token currentPoint = Token.this;

            public boolean hasNext() {
                return currentPoint.previousCachedToken() != null;
            }

            public Token next() {
                Token previous = currentPoint.previousCachedToken();
                if (previous == null) throw new java.util.NoSuchElementException("No previous token!");
                return currentPoint = previous;
            }

        };
    }

    /**
    * @return a list of the unparsed tokens preceding this one in the order they appear in the input
    */
    public List<Token> precedingUnparsedTokens() {
        List<Token> result = new ArrayList<>();
        Token t = this.previousCachedToken();
        while (t != null && t.isUnparsed()) {
            result.add(t);
            t = t.previousCachedToken();
        }
        Collections.reverse(result);
        return result;
    }

    /**
    * @return An iterator of the (cached) tokens that follow this one.
    */
    public Iterator<Token> followingTokens() {
        return new java.util.Iterator<Token>() {
            Token currentPoint = Token.this;

            public boolean hasNext() {
                return currentPoint.nextCachedToken() != null;
            }

            public Token next() {
                Token next = currentPoint.nextCachedToken();
                if (next == null) throw new java.util.NoSuchElementException("No next token!");
                return currentPoint = next;
            }

        };
    }

    public void copyLocationInfo(Token from) {
        setTokenSource(from.getTokenSource());
        setBeginOffset(from.getBeginOffset());
        setEndOffset(from.getEndOffset());
    }

    public void copyLocationInfo(Token start, Token end) {
        setTokenSource(start.getTokenSource());
        if (tokenSource == null) setTokenSource(end.getTokenSource());
        setBeginOffset(start.getBeginOffset());
        setEndOffset(end.getEndOffset());
    }

    public static Token newToken(TokenType type, SqlExprParserLexer tokenSource) {
        Token result = newToken(type, tokenSource, 0, 0);
        return result;
    }

    public static Token newToken(TokenType type, String image, SqlExprParserLexer tokenSource) {
        Token newToken = newToken(type, tokenSource);
        return newToken;
    }

    public static Token newToken(TokenType type, SqlExprParserLexer tokenSource, int beginOffset, int endOffset) {
        switch(type) {
            case OR : 
                return new OR(TokenType.OR, tokenSource, beginOffset, endOffset);
            case NULL : 
                return new NULL(TokenType.NULL, tokenSource, beginOffset, endOffset);
            case IN : 
                return new IN(TokenType.IN, tokenSource, beginOffset, endOffset);
            case FLOATING_POINT_LITERAL : 
                return new FLOATING_POINT_LITERAL(TokenType.FLOATING_POINT_LITERAL, tokenSource, beginOffset, endOffset);
            case BETWEEN : 
                return new BETWEEN(TokenType.BETWEEN, tokenSource, beginOffset, endOffset);
            case TRUE : 
                return new TRUE(TokenType.TRUE, tokenSource, beginOffset, endOffset);
            case IS : 
                return new IS(TokenType.IS, tokenSource, beginOffset, endOffset);
            case ESCAPE : 
                return new ESCAPE(TokenType.ESCAPE, tokenSource, beginOffset, endOffset);
            case NOT : 
                return new NOT(TokenType.NOT, tokenSource, beginOffset, endOffset);
            case OCTAL_LITERAL : 
                return new OCTAL_LITERAL(TokenType.OCTAL_LITERAL, tokenSource, beginOffset, endOffset);
            case LINE_COMMENT : 
                return new LINE_COMMENT(TokenType.LINE_COMMENT, tokenSource, beginOffset, endOffset);
            case BLOCK_COMMENT : 
                return new BLOCK_COMMENT(TokenType.BLOCK_COMMENT, tokenSource, beginOffset, endOffset);
            case LIKE : 
                return new LIKE(TokenType.LIKE, tokenSource, beginOffset, endOffset);
            case HEX_LITERAL : 
                return new HEX_LITERAL(TokenType.HEX_LITERAL, tokenSource, beginOffset, endOffset);
            case AND : 
                return new AND(TokenType.AND, tokenSource, beginOffset, endOffset);
            case FALSE : 
                return new FALSE(TokenType.FALSE, tokenSource, beginOffset, endOffset);
            case STRING_LITERAL : 
                return new STRING_LITERAL(TokenType.STRING_LITERAL, tokenSource, beginOffset, endOffset);
            case ID : 
                return new ID(TokenType.ID, tokenSource, beginOffset, endOffset);
            case DECIMAL_LITERAL : 
                return new DECIMAL_LITERAL(TokenType.DECIMAL_LITERAL, tokenSource, beginOffset, endOffset);
            case INVALID : 
                return new InvalidToken(tokenSource, beginOffset, endOffset);
            default : 
                return new Token(type, tokenSource, beginOffset, endOffset);
        }
    }

    public String getLocation() {
        return getInputSource() + ":" + getBeginLine() + ":" + getBeginColumn();
    }

    public Node getParent() {
        return parent;
    }

    public void setParent(Node parent) {
        this.parent = parent;
    }

    public boolean isEmpty() {
        return length() == 0;
    }

    public int length() {
        return endOffset - beginOffset;
    }

    public CharSequence subSequence(int start, int end) {
        return getTokenSource().subSequence(beginOffset + start, beginOffset + end);
    }

    public char charAt(int offset) {
        return getTokenSource().charAt(beginOffset + offset);
    }

    /**
    * @deprecated Use toString() instead
    */
    @Deprecated
    public String getImage() {
        return toString();
    }

    @Override
    public String toString() {
        String result = getSource();
        if (result == null) {
            result = getType().getLiteralString();
        }
        return result;
    }

}


